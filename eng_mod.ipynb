{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Libraries n Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-reNQe1FaIjt"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'empath'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mempath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Empath\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'empath'"
          ]
        }
      ],
      "source": [
        "from empath import Empath\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oh my gosh</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I've shifted my focus to something else but I'...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm restless and restless, it's been a month n...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement    label\n",
              "0                                         oh my gosh  Anxiety\n",
              "1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
              "2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
              "3  I've shifted my focus to something else but I'...  Anxiety\n",
              "4  I'm restless and restless, it's been a month n...  Anxiety"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"anxiety_data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6092 entries, 0 to 6091\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   statement  6092 non-null   object\n",
            " 1   label      6092 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 95.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\laila\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\laila\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\laila\\AppData\\Roaming\\nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import contractions  # For handling contractions like \"I've\" -> \"I have\"\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Add custom stopwords if needed (domain-specific words that don't carry meaning)\n",
        "custom_stopwords = {'like', 'get', 'go', 'know', 'would', 'could', 'also'}\n",
        "stop_words.update(custom_stopwords)\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Comprehensive text cleaning function that handles:\n",
        "    - Lowercasing\n",
        "    - URL removal\n",
        "    - Contraction expansion\n",
        "    - Non-ASCII character removal\n",
        "    - Number removal\n",
        "    - Punctuation removal\n",
        "    - Extra whitespace removal\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Expand contractions\n",
        "    text = contractions.fix(text)\n",
        "    \n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    \n",
        "    # Remove non-ASCII characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "    \n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    \n",
        "    # Remove punctuation\n",
        "    text = re.sub(rf\"[{re.escape(string.punctuation)}]\", '', text)\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Full text preprocessing pipeline:\n",
        "    1. Clean text\n",
        "    2. Tokenize\n",
        "    3. Remove stopwords\n",
        "    4. Lemmatize tokens\n",
        "    \"\"\"\n",
        "    # Clean the text first\n",
        "    text = clean_text(text)\n",
        "    \n",
        "    # Tokenize\n",
        "    words = text.split()\n",
        "    \n",
        "    # Remove stopwords and lemmatize\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 2:  # Remove short words\n",
        "            # Lemmatize considering part of speech (verb by default)\n",
        "            lemma = lemmatizer.lemmatize(word, pos='v')  # Try verb first\n",
        "            lemma = lemmatizer.lemmatize(lemma, pos='n')  # Then noun\n",
        "            lemma = lemmatizer.lemmatize(lemma, pos='a')  # Then adjective\n",
        "            lemma = lemmatizer.lemmatize(lemma, pos='r')  # Then adverb\n",
        "            processed_words.append(lemma)\n",
        "    \n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# Ensure the column is string type\n",
        "df['statement'] = df['statement'].astype(str)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['cleaned_statement'] = df['statement'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_statement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oh my gosh</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>gosh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>trouble sleep confuse mind restless heart tune</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>wrong back dear forward doubt stay restless re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I've shifted my focus to something else but I'...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>shift focus something else still worry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm restless and restless, it's been a month n...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>restless restless month boy mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6087</th>\n",
              "      <td>Help with your HIV, STD anxiety I recently got...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>help hiv std anxiety recently get full std tes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6088</th>\n",
              "      <td>I’ve been just kind of denying or ignoring thi...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>kind deny ignore problem awhile occasionally e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6089</th>\n",
              "      <td>Body Pulling after waking up. I woke up this m...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>body pull wake wake morning immediately slam w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6090</th>\n",
              "      <td>other health scare so about an hour ago? i wou...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>health scare hour ago say nowhere get weird cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6091</th>\n",
              "      <td>pregnancy scare i convinced myself i had gotte...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>pregnancy scare convince get pregnant use cond...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6092 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              statement    label  \\\n",
              "0                                            oh my gosh  Anxiety   \n",
              "1     trouble sleeping, confused mind, restless hear...  Anxiety   \n",
              "2     All wrong, back off dear, forward doubt. Stay ...  Anxiety   \n",
              "3     I've shifted my focus to something else but I'...  Anxiety   \n",
              "4     I'm restless and restless, it's been a month n...  Anxiety   \n",
              "...                                                 ...      ...   \n",
              "6087  Help with your HIV, STD anxiety I recently got...  Anxiety   \n",
              "6088  I’ve been just kind of denying or ignoring thi...  Anxiety   \n",
              "6089  Body Pulling after waking up. I woke up this m...  Anxiety   \n",
              "6090  other health scare so about an hour ago? i wou...  Anxiety   \n",
              "6091  pregnancy scare i convinced myself i had gotte...  Anxiety   \n",
              "\n",
              "                                      cleaned_statement  \n",
              "0                                                  gosh  \n",
              "1        trouble sleep confuse mind restless heart tune  \n",
              "2     wrong back dear forward doubt stay restless re...  \n",
              "3                shift focus something else still worry  \n",
              "4                      restless restless month boy mean  \n",
              "...                                                 ...  \n",
              "6087  help hiv std anxiety recently get full std tes...  \n",
              "6088  kind deny ignore problem awhile occasionally e...  \n",
              "6089  body pull wake wake morning immediately slam w...  \n",
              "6090  health scare hour ago say nowhere get weird cr...  \n",
              "6091  pregnancy scare convince get pregnant use cond...  \n",
              "\n",
              "[6092 rows x 3 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb5rPCFKaT_b"
      },
      "outputs": [],
      "source": [
        "lexicon = Empath()\n",
        "\n",
        "# Contoh kategori yang relevan untuk anxiety\n",
        "# emotions = ['anxiety', 'fear', 'nervousness', 'sadness', 'confusion', 'suffering', 'optimism']\n",
        "# emotions = ['anxiety', 'fear', 'nervousness', 'sadness', 'confusion', 'loneliness', 'shame', 'neglect']\n",
        "emotions = ['anxiety', 'fear', 'nervousness', 'sadness', 'confusion', 'suffering', 'shame',]\n",
        "\n",
        "def label_from_empath(text):\n",
        "    scores = lexicon.analyze(text, categories=emotions, normalize=True)\n",
        "    if scores:\n",
        "        label = max(scores, key=scores.get)\n",
        "        return label, scores\n",
        "    return \"anxiety\", {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkq2gN3DaWHH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# df[\"cleaned\"] = df[\"statement\"].astype(str).apply(preprocess_text)\n",
        "df[\"empath_label\"], df[\"empath_scores\"] = zip(*df[\"cleaned_statement\"].apply(label_from_empath))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_statement</th>\n",
              "      <th>empath_label</th>\n",
              "      <th>empath_scores</th>\n",
              "      <th>label_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oh my gosh</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>gosh</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>trouble sleep confuse mind restless heart tune</td>\n",
              "      <td>confusion</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>wrong back dear forward doubt stay restless re...</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I've shifted my focus to something else but I'...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>shift focus something else still worry</td>\n",
              "      <td>nervousness</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm restless and restless, it's been a month n...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>restless restless month boy mean</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6087</th>\n",
              "      <td>Help with your HIV, STD anxiety I recently got...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>help hiv std anxiety recently get full std tes...</td>\n",
              "      <td>nervousness</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.05063291139240506, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6088</th>\n",
              "      <td>I’ve been just kind of denying or ignoring thi...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>kind deny ignore problem awhile occasionally e...</td>\n",
              "      <td>fear</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.02564102564102564, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6089</th>\n",
              "      <td>Body Pulling after waking up. I woke up this m...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>body pull wake wake morning immediately slam w...</td>\n",
              "      <td>nervousness</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6090</th>\n",
              "      <td>other health scare so about an hour ago? i wou...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>health scare hour ago say nowhere get weird cr...</td>\n",
              "      <td>nervousness</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6091</th>\n",
              "      <td>pregnancy scare i convinced myself i had gotte...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>pregnancy scare convince get pregnant use cond...</td>\n",
              "      <td>suffering</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6092 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              statement    label  \\\n",
              "0                                            oh my gosh  Anxiety   \n",
              "1     trouble sleeping, confused mind, restless hear...  Anxiety   \n",
              "2     All wrong, back off dear, forward doubt. Stay ...  Anxiety   \n",
              "3     I've shifted my focus to something else but I'...  Anxiety   \n",
              "4     I'm restless and restless, it's been a month n...  Anxiety   \n",
              "...                                                 ...      ...   \n",
              "6087  Help with your HIV, STD anxiety I recently got...  Anxiety   \n",
              "6088  I’ve been just kind of denying or ignoring thi...  Anxiety   \n",
              "6089  Body Pulling after waking up. I woke up this m...  Anxiety   \n",
              "6090  other health scare so about an hour ago? i wou...  Anxiety   \n",
              "6091  pregnancy scare i convinced myself i had gotte...  Anxiety   \n",
              "\n",
              "                                      cleaned_statement empath_label  \\\n",
              "0                                                  gosh      anxiety   \n",
              "1        trouble sleep confuse mind restless heart tune    confusion   \n",
              "2     wrong back dear forward doubt stay restless re...      anxiety   \n",
              "3                shift focus something else still worry  nervousness   \n",
              "4                      restless restless month boy mean      anxiety   \n",
              "...                                                 ...          ...   \n",
              "6087  help hiv std anxiety recently get full std tes...  nervousness   \n",
              "6088  kind deny ignore problem awhile occasionally e...         fear   \n",
              "6089  body pull wake wake morning immediately slam w...  nervousness   \n",
              "6090  health scare hour ago say nowhere get weird cr...  nervousness   \n",
              "6091  pregnancy scare convince get pregnant use cond...    suffering   \n",
              "\n",
              "                                          empath_scores  label_encoded  \n",
              "0     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              0  \n",
              "1     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              5  \n",
              "2     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              0  \n",
              "3     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              2  \n",
              "4     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              0  \n",
              "...                                                 ...            ...  \n",
              "6087  {'anxiety': 0.0, 'fear': 0.05063291139240506, ...              2  \n",
              "6088  {'anxiety': 0.0, 'fear': 0.02564102564102564, ...              1  \n",
              "6089  {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              2  \n",
              "6090  {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              2  \n",
              "6091  {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              6  \n",
              "\n",
              "[6092 rows x 6 columns]"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "empath_label\n",
              "nervousness    3197\n",
              "fear            921\n",
              "anxiety         643\n",
              "shame           515\n",
              "suffering       430\n",
              "sadness         369\n",
              "confusion        17\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lihat distribusi emosi berdasarkan hasil Empath\n",
        "df[\"empath_label\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Buat mapping ke angka sesuai urutan\n",
        "emotion_to_index = {emotion: idx for idx, emotion in enumerate(emotions)}\n",
        "\n",
        "# Terapkan ke kolom label\n",
        "df['label_encoded'] = df['empath_label'].map(emotion_to_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_statement</th>\n",
              "      <th>empath_label</th>\n",
              "      <th>empath_scores</th>\n",
              "      <th>label_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oh my gosh</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>gosh</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>trouble sleep confuse mind restless heart tune</td>\n",
              "      <td>confusion</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>wrong back dear forward doubt stay restless re...</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I've shifted my focus to something else but I'...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>shift focus something else still worry</td>\n",
              "      <td>nervousness</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm restless and restless, it's been a month n...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>restless restless month boy mean</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6087</th>\n",
              "      <td>Help with your HIV, STD anxiety I recently got...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>help hiv std anxiety recently get full std tes...</td>\n",
              "      <td>nervousness</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.05063291139240506, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6088</th>\n",
              "      <td>I’ve been just kind of denying or ignoring thi...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>kind deny ignore problem awhile occasionally e...</td>\n",
              "      <td>fear</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.02564102564102564, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6089</th>\n",
              "      <td>Body Pulling after waking up. I woke up this m...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>body pull wake wake morning immediately slam w...</td>\n",
              "      <td>nervousness</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6090</th>\n",
              "      <td>other health scare so about an hour ago? i wou...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>health scare hour ago say nowhere get weird cr...</td>\n",
              "      <td>nervousness</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6091</th>\n",
              "      <td>pregnancy scare i convinced myself i had gotte...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>pregnancy scare convince get pregnant use cond...</td>\n",
              "      <td>suffering</td>\n",
              "      <td>{'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6092 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              statement    label  \\\n",
              "0                                            oh my gosh  Anxiety   \n",
              "1     trouble sleeping, confused mind, restless hear...  Anxiety   \n",
              "2     All wrong, back off dear, forward doubt. Stay ...  Anxiety   \n",
              "3     I've shifted my focus to something else but I'...  Anxiety   \n",
              "4     I'm restless and restless, it's been a month n...  Anxiety   \n",
              "...                                                 ...      ...   \n",
              "6087  Help with your HIV, STD anxiety I recently got...  Anxiety   \n",
              "6088  I’ve been just kind of denying or ignoring thi...  Anxiety   \n",
              "6089  Body Pulling after waking up. I woke up this m...  Anxiety   \n",
              "6090  other health scare so about an hour ago? i wou...  Anxiety   \n",
              "6091  pregnancy scare i convinced myself i had gotte...  Anxiety   \n",
              "\n",
              "                                      cleaned_statement empath_label  \\\n",
              "0                                                  gosh      anxiety   \n",
              "1        trouble sleep confuse mind restless heart tune    confusion   \n",
              "2     wrong back dear forward doubt stay restless re...      anxiety   \n",
              "3                shift focus something else still worry  nervousness   \n",
              "4                      restless restless month boy mean      anxiety   \n",
              "...                                                 ...          ...   \n",
              "6087  help hiv std anxiety recently get full std tes...  nervousness   \n",
              "6088  kind deny ignore problem awhile occasionally e...         fear   \n",
              "6089  body pull wake wake morning immediately slam w...  nervousness   \n",
              "6090  health scare hour ago say nowhere get weird cr...  nervousness   \n",
              "6091  pregnancy scare convince get pregnant use cond...    suffering   \n",
              "\n",
              "                                          empath_scores  label_encoded  \n",
              "0     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              0  \n",
              "1     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              4  \n",
              "2     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              0  \n",
              "3     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              2  \n",
              "4     {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              0  \n",
              "...                                                 ...            ...  \n",
              "6087  {'anxiety': 0.0, 'fear': 0.05063291139240506, ...              2  \n",
              "6088  {'anxiety': 0.0, 'fear': 0.02564102564102564, ...              1  \n",
              "6089  {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              2  \n",
              "6090  {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              2  \n",
              "6091  {'anxiety': 0.0, 'fear': 0.0, 'nervousness': 0...              5  \n",
              "\n",
              "[6092 rows x 6 columns]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDd1SALBcnd8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Konversi label encoded ke one-hot\n",
        "y = to_categorical(df['label_encoded'])\n",
        "\n",
        "# 2. Tokenisasi teks\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['cleaned_statement'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df['cleaned_statement'])\n",
        "X = pad_sequences(sequences, maxlen=100)\n",
        "\n",
        "# 3. Split data untuk training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['label_encoded']  # Penting biar distribusi label tetap\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuHG-1bzafdt",
        "outputId": "f7a3637a-21c4-46e2-db25-e12f36e69d91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\eng-model\\engmod\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_18                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer_2               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_20 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_18                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer_2               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.4100 - loss: 1.7479 - precision_2: 0.3925 - recall_2: 0.0633 - val_accuracy: 0.5221 - val_loss: 1.4382 - val_precision_2: 0.4970 - val_recall_2: 0.2564 - learning_rate: 5.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5319 - loss: 1.4629 - precision_2: 0.5145 - recall_2: 0.2006 - val_accuracy: 0.5221 - val_loss: 1.2995 - val_precision_2: 0.6055 - val_recall_2: 0.3415 - learning_rate: 5.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.5159 - loss: 1.3547 - precision_2: 0.6134 - recall_2: 0.3064 - val_accuracy: 0.5303 - val_loss: 1.1739 - val_precision_2: 0.7358 - val_recall_2: 0.4913 - learning_rate: 5.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.5562 - loss: 1.1669 - precision_2: 0.7898 - recall_2: 0.4029 - val_accuracy: 0.6451 - val_loss: 1.0335 - val_precision_2: 0.7784 - val_recall_2: 0.5621 - learning_rate: 5.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.6588 - loss: 0.9638 - precision_2: 0.8505 - recall_2: 0.5301 - val_accuracy: 0.6759 - val_loss: 0.8980 - val_precision_2: 0.8604 - val_recall_2: 0.5436 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.7085 - loss: 0.8072 - precision_2: 0.9010 - recall_2: 0.5607 - val_accuracy: 0.7508 - val_loss: 0.7975 - val_precision_2: 0.8456 - val_recall_2: 0.6236 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.7794 - loss: 0.6324 - precision_2: 0.9021 - recall_2: 0.6510 - val_accuracy: 0.7764 - val_loss: 0.7324 - val_precision_2: 0.8322 - val_recall_2: 0.7221 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.8057 - loss: 0.5667 - precision_2: 0.8807 - recall_2: 0.7340 - val_accuracy: 0.6615 - val_loss: 0.9035 - val_precision_2: 0.7493 - val_recall_2: 0.5703 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7377 - loss: 0.6768 - precision_2: 0.8446 - recall_2: 0.6415\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 99ms/step - accuracy: 0.7381 - loss: 0.6760 - precision_2: 0.8448 - recall_2: 0.6419 - val_accuracy: 0.7426 - val_loss: 0.8095 - val_precision_2: 0.8069 - val_recall_2: 0.6687 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.8062 - loss: 0.5150 - precision_2: 0.8851 - recall_2: 0.7228 - val_accuracy: 0.7928 - val_loss: 0.8084 - val_precision_2: 0.8481 - val_recall_2: 0.7272 - learning_rate: 2.5000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8419 - loss: 0.4479 - precision_2: 0.9126 - recall_2: 0.7698"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     67\u001b[39m model.summary()\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Training with class weights if imbalance exists\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Increased max epochs\u001b[39;49;00m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Increased batch size\u001b[39;49;00m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearlystop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Add if you have imbalanced classes\u001b[39;49;00m\n\u001b[32m     77\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:401\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_eval_epoch_iterator\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    391\u001b[39m     \u001b[38;5;28mself\u001b[39m._eval_epoch_iterator = TFEpochIterator(\n\u001b[32m    392\u001b[39m         x=val_x,\n\u001b[32m    393\u001b[39m         y=val_y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    399\u001b[39m         shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    400\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m val_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m val_logs = {\n\u001b[32m    412\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval_\u001b[39m\u001b[33m\"\u001b[39m + name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs.items()\n\u001b[32m    413\u001b[39m }\n\u001b[32m    414\u001b[39m epoch_logs.update(val_logs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:489\u001b[39m, in \u001b[36mTensorFlowTrainer.evaluate\u001b[39m\u001b[34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    488\u001b[39m     callbacks.on_test_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m     callbacks.on_test_batch_end(step, logs)\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_evaluating:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\eng-model\\engmod\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
        "from tensorflow.keras.layers import Layer  # For custom attention layer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Custom Attention Layer (since Keras doesn't have a built-in standalone Attention layer for this use case)\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', \n",
        "                               shape=(input_shape[-1], 1),\n",
        "                               initializer='random_normal',\n",
        "                               trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias',\n",
        "                                shape=(input_shape[1], 1),\n",
        "                                initializer='zeros',\n",
        "                                trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        # Alignment scores\n",
        "        e = tf.tanh(tf.matmul(x, self.W) + self.b)\n",
        "        # Attention weights\n",
        "        alpha = tf.nn.softmax(e, axis=1)\n",
        "        # Context vector\n",
        "        context = x * alpha\n",
        "        context = tf.reduce_sum(context, axis=1)\n",
        "        return context\n",
        "\n",
        "# Callbacks\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  # Increased patience\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_lr=1e-5)\n",
        "\n",
        "# Model Architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer (consider using pre-trained embeddings)\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
        "\n",
        "# Bidirectional LSTM with return_sequences=True for Attention\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "\n",
        "# Custom Attention Layer\n",
        "model.add(AttentionLayer())\n",
        "\n",
        "# Dropout with reduced rate (from 0.6 to 0.5)\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))  # Increased from 32 to 64\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "# Optimizer with lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reduced from 0.001\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=optimizer, \n",
        "              metrics=['accuracy', \n",
        "                      tf.keras.metrics.Precision(),\n",
        "                      tf.keras.metrics.Recall()])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Training with class weights if imbalance exists\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,  # Increased max epochs\n",
        "    batch_size=64,  # Increased batch size\n",
        "    validation_split=0.2,\n",
        "    callbacks=[earlystop, reduce_lr],\n",
        "    # Add if you have imbalanced classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqPG-f38cwWc",
        "outputId": "29876dbb-971c-4594-bc6e-e570fd13ee2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7834 - loss: 0.8393 - precision_1: 0.8296 - recall_1: 0.7560\n",
            "Test Accuracy: 0.7744\n",
            "Test Precision: 0.8196\n",
            "Test Recall: 0.7416\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.84      0.79       129\n",
            "           1       0.68      0.70      0.69       184\n",
            "           2       0.90      0.91      0.91       640\n",
            "           4       0.33      0.20      0.25        74\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.51      0.44      0.47        86\n",
            "           7       0.61      0.66      0.64       103\n",
            "\n",
            "    accuracy                           0.77      1219\n",
            "   macro avg       0.54      0.54      0.54      1219\n",
            "weighted avg       0.76      0.77      0.77      1219\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[109   8   7   3   0   1   1]\n",
            " [ 22 129  20   6   0   5   2]\n",
            " [  1  26 585   0   0   4  24]\n",
            " [  5  15  11  15   0  20   8]\n",
            " [  3   0   0   0   0   0   0]\n",
            " [  5   8   7  20   0  38   8]\n",
            " [  3   3  22   1   0   6  68]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\eng-model\\engmod\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "d:\\eng-model\\engmod\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "d:\\eng-model\\engmod\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Evaluasi Model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Mengonversi prediksi ke kelas sebenarnya\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print akurasi dasar\n",
        "test_loss, test_acc, test_precision, test_recall = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "\n",
        "# Laporan klasifikasi\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes))\n",
        "\n",
        "# Matriks kebingungan (Confusion Matrix)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_true_classes, y_pred_classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"emotion_model_v1.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
